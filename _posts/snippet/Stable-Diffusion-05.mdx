---
title: "[Stable Diffusion] - 5"
description: "대상의 포즈"
language: "StableDiffusion"
category: "Generative AI"
update: "2024-03-04"
hide: true
serisenumber: 5
---

### ControlNet

순정 Stable-diffusion으로만으로는 특정 포즈로 대상을 그리기는 쉽지 않습니다. [ControlNet](https://github.com/lllyasviel/ControlNet)이 그 대안입니다. `Extension`탭에서 like순으로 조회하면 최상단에 보일겁니다. `INSTALL`버튼을 눌러 익스텐션을 설치합니다. 이후 `Apply and quit`버튼을 눌러 재가동합니다.

4GB 이하의 `VRAM`을 사용하는 경우 `webui-user-my.bat`파일을 텍스트로 열어 다음 옵션을 적용합니다.

```bat
set COMMANDLINE_ARGS=--lowvram --xformers
```

이제 모델을 다운로드하여 적용해야합니다. `ControlNet`만으로는 사용이 불가능합니다.

- [ControlNet-modules-safetensors at main](https://huggingface.co/webui/ControlNet-modules-safetensors/tree/main)

`control_...-fp16.safetensors` 파일 총 8개를 받아 `[설치 폴더]/models/ControlNet`폴더로 이동합니다.

### ControlNet 사용법

![stable-diffusion-webui-controlnet-menu](/snippets/stableDiffusion/section5/controlnet-menu.png)

Image 영역에는 생성될 이미지 대상의 위치 및 포즈로 사용할 이미지를 업로드 합니다. `Enable`을 체크하여 ControlNet으로 적용되도록 하고 `Low VRAM`을 체크하여 낮은 VRAM환경에서도 작동되도록 할 수 있습니다.

선택된 `Control Type`에 따라 적합한 `Preprocessor`, `Model`이 선택됩니다. 필요한 경우 직접 모델 및 프리프로세서를 선택해도 됩니다.

`ControlNet`에서는 `Preprocessor`에서 선택한 형식으로 업로드한 피사체의 이미지를 전처리해 중간 이미지를 만듭니다. 그리고 중간 이미지를 바탕으로 Model에서 처리해 이미지 생성을 제어합니다.

`Preprocessor`를 건너뛸 경우 `node`을 선택하면 됩니다.

어떤 `Model`이 있는지 확인해봅시다.

#### canny

입력 이미지 윤곽선을 추출해 선에 따른 이미지를 생성하빈다. 2차원 일러스트, 3D이미지에 적합합니다. 포즈를 잘 잡아줍니다.

#### depth

입력 이미지의 깊이 정보를 추출해 심도에 따라 이미지를 생성합니다. 카메라로 촬영한 사진에 적합하며 깊이를 가진 이미지 생성시 유용합니다..

#### hed

입력 이미지의 가장자리를 감지해 대략적인 윤곽을 추출합니다. 원본 이미지 크기에 영향을 받으므로 색상를 변경하는 용도로 주로 이용합니다. 포즈 및 깊이 있는 이미지 생성시에는 적용하지 않습니다.

#### mlsd

입력 이미지의 직선을 검출해 직선으로 구성된 이미지를 추출합니다. 실내 이미지에서 추출한 직선 정보를 사용해 동일 구도 실내 이미지를 만드는 용도로 주로 이용합니다. 건물이나 실내 이미지에서 사용합니다.

#### normal_map

입력 이미지의 요철을 감지해 비슷한 입체 구조를 가진 이미지를 생성합니다. 배경은 대부분 무시되며 3D 드로잉 인형, 마네킹 사진과 같은 이미지로 포즈를 취하는 데 적합합니다.

#### openpose

입력 이미지에서 색이 있는 막대 이미지를 만들어 그 모양에 따라 이미지를 생성합니다. 관절 위치를 정교하게 인식합니다.

#### scribble

낙서를 바탕으로 포즈를 재현해 줍니다. 선으로 적당히 그려도 제대로 인식합니다.

#### segmentation

사진에서 영역을 감지해 영역에 맞는 이미지를 생성합니다. 사진의 레이아웃에 따라 건물을 다르게 만드는 등의 용도로 사용합니다.

### 여러 모델 이용하기

프롬프트는 다음을 공통으로 사용하겠습니다.

```text
<!-- Prompt -->
masterpiece, best quality, concept art, extremely datailed,
(watercolor:1.2), (oil painting:1.1)
one fantasy girl, young little girl, (long wavy hair:1.8), (dress costume:1.9),
beautiful perfect symmetrical face, small nose and mouth, aesthetic eyes, sharp focus, realism, 8k,
(style of granblue fantasy: 1.1), (style of genshin impect:0.9),
(style of renaissance:0.7), (style of gothic: 0.6), (style of high fantasy:0.5),
artstation, deviantart, pixiv ranking 1st
```

```text
<!-- Negative Prompt -->
bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits,
cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, water-mark,
username, blurry, missing fingers, missing arms, long neck, humpbacked,
shadow, flat shading, flat color, grayscale, black&white, monochrome, animal ears
```

### canny 생성

canny는 이미지를 처리할 때 중간 이미지로 선화(색을 칠하지 않은)를 만들어 이미지를 생성합니다. 주의할점은 선의 경유 윤곽(바깥)부분만 존재하는게 좋습니다. 신체 내부에 선 모양이 강하다면 이미지 생성시에도 선이 그대로 남아있습니다. 

![stable-diffusion-webui-canny-image](/snippets/stableDiffusion/section5/canny-image.png)

한번 실행하면 중간 이미지는 생성되므로 `Prepocessor`는 `none`옵션을 설정할 수 있습니다.